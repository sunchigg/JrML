{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import numpy as numpy\n",
    "import ffm\n",
    "import _pickle as pickle\n",
    "#import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastFM.mcmc import FMClassification, FMRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.datasets import dump_svmlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fields\n",
    "* Label - Target variable that indicates if an ad was clicked (1) or not (0).\n",
    "* I1-I13 - A total of 13 columns of integer features (mostly count features).\n",
    "* C1-C26 - A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pandas.read_csv('./train.tiny.csv')\n",
    "test_data = pandas.read_csv('./test.tiny.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料格式\n",
    "* df = Dataframe to be converted to ffm format\n",
    "* Type = Train/Test/Val\n",
    "* Numerics = list of all numeric fields\n",
    "* Categories = list of all categorical fields\n",
    "* Features = list of all features except the Label and Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Kaggle kernel by Scirpus\n",
    "def convert_to_ffm(df,type,numerics,categories,features):\n",
    "    currentcode = len(numerics)\n",
    "    catdict = {}\n",
    "    catcodes = {}\n",
    "    # Flagging categorical and numerical fields\n",
    "    for x in numerics:\n",
    "         catdict[x] = 0\n",
    "    for x in categories:\n",
    "         catdict[x] = 1\n",
    "    \n",
    "    nrows = df.shape[0]\n",
    "    ncolumns = len(features)\n",
    "    with open(str(type) + \"_ffm.txt\", \"w\") as text_file:\n",
    "# Looping over rows to convert each row to libffm format\n",
    "        for n,r in enumerate(range(nrows)):\n",
    "            datastring = \"\"\n",
    "            datarow = df.iloc[r].to_dict()\n",
    "            datastring += str(int(datarow['Label']))\n",
    "             # For numerical fields, we are creating a dummy field here\n",
    "            for i, x in enumerate(catdict.keys()):\n",
    "                if(catdict[x]==0):\n",
    "                    datastring = datastring + \" \"+str(i)+\":\"+ str(i)+\":\"+ str(datarow[x])\n",
    "                else:\n",
    "            # For a new field appearing in a training example\n",
    "                    if(x not in catcodes):\n",
    "                        catcodes[x] = {}\n",
    "                        currentcode +=1\n",
    "                        catcodes[x][datarow[x]] = currentcode #encoding the feature\n",
    "            # For already encoded fields\n",
    "                    elif(datarow[x] not in catcodes[x]):\n",
    "                        currentcode +=1\n",
    "                        catcodes[x][datarow[x]] = currentcode #encoding the feature\n",
    "                    code = catcodes[x][datarow[x]]\n",
    "                    datastring = datastring + \" \"+str(i)+\":\"+ str(int(code))+\":1\"\n",
    "\n",
    "            datastring += '\\n'\n",
    "            text_file.write(datastring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         I1   I2         I3         I4      I5          I6    I7   I8     I9  \\\n",
      "0  1.000000    1   5.000000   0.000000  1382.0    4.000000  15.0  2.0  181.0   \n",
      "1  2.000000    0  44.000000   1.000000   102.0    8.000000   2.0  2.0    4.0   \n",
      "2  2.000000    0   1.000000  14.000000   767.0   89.000000   4.0  2.0  245.0   \n",
      "3  3.696396  893  33.079355   8.062698  4392.0  146.925631   0.0  0.0    0.0   \n",
      "4  3.000000   -1  33.079355   0.000000     2.0    0.000000   3.0  0.0    0.0   \n",
      "\n",
      "        I10  I11       I12        I13  \n",
      "0  1.000000  2.0  1.042697   2.000000  \n",
      "1  1.000000  1.0  1.042697   4.000000  \n",
      "2  1.000000  3.0  3.000000  45.000000  \n",
      "3  0.561261  0.0  1.042697  11.784674  \n",
      "4  1.000000  1.0  1.042697   0.000000  \n",
      "\n",
      "\n",
      "         C1        C2        C3        C4        C5        C6        C7  \\\n",
      "0  68fd1e64  80e26c9b  fb936136  7b4723c4  25c83c98  7e0ccccf  de7995b8   \n",
      "1  68fd1e64  f0cf0024  6f67f7e5  41274cd7  25c83c98  fe6b92e5  922afcc0   \n",
      "2  287e684f  0a519c5c  02cf9876  c18be181  25c83c98  7e0ccccf  c78204a1   \n",
      "3  68fd1e64  2c16a946  a9a87e68  2e17d6f6  25c83c98  fe6b92e5  2e8a689b   \n",
      "4  8cf07265  ae46a29d  c81688bb  f922efad  25c83c98  13718bbd  ad9fa255   \n",
      "\n",
      "         C8        C9       C10    ...          C17       C18       C19  \\\n",
      "0  1f89b562  a73ee510  a8cd5504    ...     e5ba7672  f54016b9  21ddcdc9   \n",
      "1  0b153874  a73ee510  2b53e5fb    ...     07c540c4  b04e4670  21ddcdc9   \n",
      "2  0b153874  a73ee510  3b08e48b    ...     8efede7f  3412118d         0   \n",
      "3  0b153874  a73ee510  efea433b    ...     1e88c74f  74ef3502         0   \n",
      "4  0b153874  a73ee510  5282c137    ...     1e88c74f  26b3c7a7         0   \n",
      "\n",
      "        C20       C21       C22       C23       C24       C25       C26  \n",
      "0  b1252a9d  07b5194c         0  3a171ecb  c5c50484  e8b83407  9727dd16  \n",
      "1  5840adea  60f6221e         0  3a171ecb  43f13e8b  e8b83407  731c3655  \n",
      "2         0  e587c466  ad3062eb  3a171ecb  3b183c5c         0         0  \n",
      "3         0  6b3a5ca6         0  3a171ecb  9117a34a         0         0  \n",
      "4         0  21c9516a         0  32c7478e  b34f3128         0         0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "\n",
      "         I1   I2         I3         I4      I5          I6    I7   I8     I9  \\\n",
      "0  1.000000    1   5.000000   0.000000  1382.0    4.000000  15.0  2.0  181.0   \n",
      "1  2.000000    0  44.000000   1.000000   102.0    8.000000   2.0  2.0    4.0   \n",
      "2  2.000000    0   1.000000  14.000000   767.0   89.000000   4.0  2.0  245.0   \n",
      "3  3.696396  893  33.079355   8.062698  4392.0  146.925631   0.0  0.0    0.0   \n",
      "4  3.000000   -1  33.079355   0.000000     2.0    0.000000   3.0  0.0    0.0   \n",
      "\n",
      "        I10    ...          C17       C18       C19       C20       C21  \\\n",
      "0  1.000000    ...     e5ba7672  f54016b9  21ddcdc9  b1252a9d  07b5194c   \n",
      "1  1.000000    ...     07c540c4  b04e4670  21ddcdc9  5840adea  60f6221e   \n",
      "2  1.000000    ...     8efede7f  3412118d         0         0  e587c466   \n",
      "3  0.561261    ...     1e88c74f  74ef3502         0         0  6b3a5ca6   \n",
      "4  1.000000    ...     1e88c74f  26b3c7a7         0         0  21c9516a   \n",
      "\n",
      "        C22       C23       C24       C25       C26  \n",
      "0         0  3a171ecb  c5c50484  e8b83407  9727dd16  \n",
      "1         0  3a171ecb  43f13e8b  e8b83407  731c3655  \n",
      "2  ad3062eb  3a171ecb  3b183c5c         0         0  \n",
      "3         0  3a171ecb  9117a34a         0         0  \n",
      "4         0  32c7478e  b34f3128         0         0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "num_col_tr = train_data.iloc[:,2:15]\n",
    "cat_col_tr = train_data.iloc[:,15:41]\n",
    "#all_col_tr = train_data.drop(['Id','Label'],axis=1)\n",
    "\n",
    "num_col_tr = pandas.DataFrame(num_col_tr.fillna(num_col_tr.mean()))\n",
    "cat_col_tr = pandas.DataFrame(cat_col_tr.fillna(0))\n",
    "all_col_tr = pandas.concat([num_col_tr,cat_col_tr],axis=1)\n",
    "\n",
    "print (num_col_tr.head())\n",
    "print ('\\n')\n",
    "print (cat_col_tr.head())\n",
    "print ('\\n')\n",
    "print (all_col_tr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 13)\n",
      "(1999, 26)\n",
      "(1999, 39)\n"
     ]
    }
   ],
   "source": [
    "num_col_te = test_data.iloc[:,2:15]\n",
    "cat_col_te = test_data.iloc[:,15:41]\n",
    "#all_col_te = test_data.drop(['Id','Label'],axis=1)\n",
    "\n",
    "num_col_te = pandas.DataFrame(num_col_te.fillna(num_col_tr.mean()))\n",
    "cat_col_te = pandas.DataFrame(cat_col_te.fillna(0))\n",
    "all_col_te = pandas.concat([num_col_te,cat_col_te],axis=1)\n",
    "\n",
    "print (num_col_te.shape)\n",
    "print (cat_col_te.shape)\n",
    "print (all_col_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_Label = pandas.concat([train_data.Label,all_col_tr],axis=1)\n",
    "convert_to_ffm(train_data_Label,'Train',list(num_col_tr),list(cat_col_tr),list(all_col_tr))\n",
    "\n",
    "test_data_Label = pandas.concat([test_data.Label,all_col_te],axis=1)\n",
    "convert_to_ffm(test_data_Label,'Test',list(num_col_te),list(cat_col_te),list(all_col_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_model = xl.create_fm() # Use field-aware factorization machine\n",
    "fm_model.setTrain(\"Train_ffm.txt\")  # Training data\n",
    "fm_model.setValidate(\"Test_ffm.txt\")  # Validation data\n",
    "# param:\n",
    "#  0. binary classification\n",
    "#  1. learning rate : 0.2\n",
    "#  2. regular lambda : 0.002\n",
    "param = {'task':'binary', 'lr':0.2, 'lambda':0.002,  'metric':'acc'}\n",
    "# Train model\n",
    "fm_model.fit(param, \"./model_fm.out\")\n",
    "\n",
    "# Prediction task\n",
    "fm_model.setTest(\"Test_ffm.txt\")  # Test data\n",
    "fm_model.setSigmoid()  # Convert output to 0-1\n",
    "\n",
    "# Start to predict\n",
    "# The output result will be stored in output.txt\n",
    "fm_model.predict(\"./model_fm.out\", \"./output_fm.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ffm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training task\n",
    "ffm_model = xl.create_ffm() # Use field-aware factorization machine\n",
    "ffm_model.setTrain(\"Train_ffm.txt\")  # Training data\n",
    "ffm_model.setValidate(\"Test_ffm.txt\")  # Validation data\n",
    "\n",
    "# param:\n",
    "#  0. binary classification\n",
    "#  1. learning rate: 0.2\n",
    "#  2. regular lambda: 0.002\n",
    "#  3. evaluation metric: accuracy\n",
    "param = {'task':'binary', 'lr':0.2, \n",
    "         'lambda':0.002, 'metric':'acc'}\n",
    "\n",
    "# Start to train\n",
    "# The trained model will be stored in model.out\n",
    "ffm_model.fit(param, './model.out')\n",
    "\n",
    "# Prediction task\n",
    "ffm_model.setTest(\"Test_ffm.txt\")  # Test data\n",
    "ffm_model.setSigmoid()  # Convert output to 0-1\n",
    "\n",
    "# Start to predict\n",
    "# The output result will be stored in output.txt\n",
    "ffm_model.predict(\"./model.out\", \"./output_ffm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install git+https://github.com/coreylynch/pyFM\n",
    "from pyfm import pylibfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpredict_logistic(trainX, trainY, testX, classification=True, **params):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(trainX)\n",
    "    trainX = encoder.transform(trainX)\n",
    "    testX = encoder.transform(testX)\n",
    "    if classification:\n",
    "        clf = LogisticRegression(**params)\n",
    "        clf.fit(trainX, trainY)\n",
    "        return clf.predict_proba(testX)[:, 1]\n",
    "    else:\n",
    "        clf = Ridge(**params)\n",
    "        clf.fit(trainX, trainY)\n",
    "        return clf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpredict_libfm(trainX, trainY, testX, classification=True, rank=8, n_iter=100):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(trainX)\n",
    "    trainX = encoder.transform(trainX)\n",
    "    testX = encoder.transform(testX)\n",
    "    train_file = 'libfm_train.txt'\n",
    "    test_file = 'libfm_test.txt'\n",
    "    with open(train_file, 'w') as f:\n",
    "        dump_svmlight_file(trainX, trainY, f=f)\n",
    "    with open(test_file, 'w') as f:\n",
    "        dump_svmlight_file(testX, numpy.zeros(testX.shape[0]), f=f)\n",
    "    task = 'c' if classification else 'r'\n",
    "    console_output = !$LIBFM_PATH -task $task -method mcmc -train $train_file -test $test_file -iter $n_iter -dim '1,1,$rank' -out output.libfm\n",
    "    \n",
    "    libfm_pred = pandas.read_csv('output.libfm', header=None).values.flatten()\n",
    "    return libfm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpredict_fastfm(trainX, trainY, testX, classification=True, rank=8, n_iter=100):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(trainX)\n",
    "    trainX = encoder.transform(trainX)\n",
    "    testX = encoder.transform(testX)\n",
    "    if classification:\n",
    "        clf = FMClassification(rank=rank, n_iter=n_iter)\n",
    "        return clf.fit_predict_proba(trainX, trainY, testX)\n",
    "    else:\n",
    "        clf = FMRegression(rank=rank, n_iter=n_iter)\n",
    "        return clf.fit_predict(trainX, trainY, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpredict_pylibfm(trainX, trainY, testX, classification=True, rank=8, n_iter=10):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(trainX)\n",
    "    trainX = encoder.transform(trainX)\n",
    "    testX = encoder.transform(testX)\n",
    "    task = 'classification' if classification else 'regression'\n",
    "    fm = pylibfm.FM(num_factors=rank, num_iter=n_iter, verbose=False, task=task)\n",
    "    if classification:\n",
    "        fm.fit(trainX, trainY)\n",
    "    else:\n",
    "        fm.fit(trainX, trainY * 1.)\n",
    "    return fm.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    if(train_data[col].dtypes) != 'object':\n",
    "        train_data.loc[:,col] = train_data.loc[:,col].fillna(0)\n",
    "for col in test_data.columns:\n",
    "    if(test_data[col].dtypes) != 'object':\n",
    "        test_data.loc[:,col] = test_data.loc[:,col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from fastFM.mcmc import FMClassification, FMRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyfm import pylibfm\n",
    "import sys\n",
    "import _pickle as cPickle\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train_data.drop(['Id','Label'],axis = 1) \n",
    "trainY = train_data.Label\n",
    "testX = test_data.drop(['Id','Label'],axis = 1) \n",
    "testY = test_data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_t = trainX.drop(cat_col_tr,axis = 1) \n",
    "trainY_t = train_data.Label\n",
    "testX_t = testX.drop(cat_col_te,axis = 1) \n",
    "testY_t = test_data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_t = abs(trainX_t)\n",
    "trainY_t = abs(trainY_t)\n",
    "testX_t = abs(testX_t)\n",
    "testY_t = abs(testY_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://arogozhnikov.github.io/2016/02/15/TestingLibFM.html\n",
    "#Below is simple mechanism, which preserves results between runs.\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "all_results = OrderedDict()\n",
    "try:\n",
    "    with open('./saved_results.pkl') as f:\n",
    "        all_results = pickle.load(f)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def test_on_dataset(trainX, testX, trainY, testY, task_name, classification=True, use_pylibfm=True):\n",
    "    algorithms = OrderedDict()\n",
    "    algorithms['logistic'] = fitpredict_logistic\n",
    "    algorithms['libFM']    = fitpredict_libfm\n",
    "    algorithms['fastFM']   = fitpredict_fastfm\n",
    "    if use_pylibfm:\n",
    "        algorithms['pylibfm']  = fitpredict_pylibfm\n",
    "    \n",
    "    results = pandas.DataFrame()\n",
    "    for name, fit_predict in algorithms.items():\n",
    "        start = time.time()\n",
    "        predictions = fit_predict(trainX, trainY, testX, classification=classification)\n",
    "        spent_time = time.time() - start\n",
    "        results.ix[name, 'time'] = spent_time\n",
    "        if classification:\n",
    "            results.ix[name, 'ROC AUC'] = roc_auc_score(testY, predictions)\n",
    "        else:\n",
    "            results.ix[name, 'RMSE'] = numpy.mean((testY - predictions) ** 2) ** 0.5\n",
    "            \n",
    "    all_results[task_name] = results\n",
    "    with open('saved_results.pkl', 'w') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = load_problems.load_problem_movielens_100k(all_features=False)\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
