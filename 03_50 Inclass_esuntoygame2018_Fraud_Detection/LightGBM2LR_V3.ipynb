{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv',encoding='big5')\n",
    "class1 = train[train.Class==1]\n",
    "class0 = train[train.Class==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# duplicate fraud case: 2 times\n",
    "train= class0.append([class1,class1], ignore_index=True)\n",
    "test= pd.read_csv('test_public.csv',encoding='big5')\n",
    "# append in ONE data\n",
    "test = test.dropna()\n",
    "data=train.append(test, ignore_index=True)\n",
    "del (class0,class1,train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing data by Class\n",
    "dataTrain = data[pd.notnull(data['Class'])]#.sort_values(by=[\"Time\"])\n",
    "dataTest = data[~pd.notnull(data['Class'])]#.sort_values(by=[\"Time\"])\n",
    "dataTrain.columns\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTrain = dataTrain.drop(['Time'], axis=1)\n",
    "dataTest = dataTest.drop(['TXKEY','Class'], axis=1)\n",
    "X_feature = dataTrain.drop(['TXKEY','Class'], axis=1)\n",
    "y_t =dataTrain['Class']\n",
    "del dataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y_t, test_size=0.33, random_state=2884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_val = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 64,\n",
    "    'num_trees': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "num_leaf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:102: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.0157037\n",
      "[2]\ttraining's binary_logloss: 0.014978\n",
      "[3]\ttraining's binary_logloss: 0.0144075\n",
      "[4]\ttraining's binary_logloss: 0.0139119\n",
      "[5]\ttraining's binary_logloss: 0.0134584\n",
      "[6]\ttraining's binary_logloss: 0.0130036\n",
      "[7]\ttraining's binary_logloss: 0.0126051\n",
      "[8]\ttraining's binary_logloss: 0.0122215\n",
      "[9]\ttraining's binary_logloss: 0.0118904\n",
      "[10]\ttraining's binary_logloss: 0.0115731\n",
      "[11]\ttraining's binary_logloss: 0.0112641\n",
      "[12]\ttraining's binary_logloss: 0.0109791\n",
      "[13]\ttraining's binary_logloss: 0.0107087\n",
      "[14]\ttraining's binary_logloss: 0.0104751\n",
      "[15]\ttraining's binary_logloss: 0.0102461\n",
      "[16]\ttraining's binary_logloss: 0.0100247\n",
      "[17]\ttraining's binary_logloss: 0.00981905\n",
      "[18]\ttraining's binary_logloss: 0.00962466\n",
      "[19]\ttraining's binary_logloss: 0.00943474\n",
      "[20]\ttraining's binary_logloss: 0.00925718\n",
      "[21]\ttraining's binary_logloss: 0.00908843\n",
      "[22]\ttraining's binary_logloss: 0.00892642\n",
      "[23]\ttraining's binary_logloss: 0.008769\n",
      "[24]\ttraining's binary_logloss: 0.00861902\n",
      "[25]\ttraining's binary_logloss: 0.00847242\n",
      "[26]\ttraining's binary_logloss: 0.00832837\n",
      "[27]\ttraining's binary_logloss: 0.00818487\n",
      "[28]\ttraining's binary_logloss: 0.00804883\n",
      "[29]\ttraining's binary_logloss: 0.00791979\n",
      "[30]\ttraining's binary_logloss: 0.00779643\n",
      "[31]\ttraining's binary_logloss: 0.00766998\n",
      "[32]\ttraining's binary_logloss: 0.00755103\n",
      "[33]\ttraining's binary_logloss: 0.0074352\n",
      "[34]\ttraining's binary_logloss: 0.00732393\n",
      "[35]\ttraining's binary_logloss: 0.00721562\n",
      "[36]\ttraining's binary_logloss: 0.00710965\n",
      "[37]\ttraining's binary_logloss: 0.00700348\n",
      "[38]\ttraining's binary_logloss: 0.00690064\n",
      "[39]\ttraining's binary_logloss: 0.00680126\n",
      "[40]\ttraining's binary_logloss: 0.00670425\n",
      "[41]\ttraining's binary_logloss: 0.00661026\n",
      "[42]\ttraining's binary_logloss: 0.00651891\n",
      "[43]\ttraining's binary_logloss: 0.00643266\n",
      "[44]\ttraining's binary_logloss: 0.00634372\n",
      "[45]\ttraining's binary_logloss: 0.00625675\n",
      "[46]\ttraining's binary_logloss: 0.00617258\n",
      "[47]\ttraining's binary_logloss: 0.00609132\n",
      "[48]\ttraining's binary_logloss: 0.00601324\n",
      "[49]\ttraining's binary_logloss: 0.00593756\n",
      "[50]\ttraining's binary_logloss: 0.00586142\n",
      "[51]\ttraining's binary_logloss: 0.00578343\n",
      "[52]\ttraining's binary_logloss: 0.00570785\n",
      "[53]\ttraining's binary_logloss: 0.00563526\n",
      "[54]\ttraining's binary_logloss: 0.00556484\n",
      "[55]\ttraining's binary_logloss: 0.00549623\n",
      "[56]\ttraining's binary_logloss: 0.005426\n",
      "[57]\ttraining's binary_logloss: 0.00535729\n",
      "[58]\ttraining's binary_logloss: 0.00529116\n",
      "[59]\ttraining's binary_logloss: 0.00522682\n",
      "[60]\ttraining's binary_logloss: 0.00516255\n",
      "[61]\ttraining's binary_logloss: 0.00510075\n",
      "[62]\ttraining's binary_logloss: 0.00503963\n",
      "[63]\ttraining's binary_logloss: 0.00497925\n",
      "[64]\ttraining's binary_logloss: 0.00492053\n",
      "[65]\ttraining's binary_logloss: 0.00486267\n",
      "[66]\ttraining's binary_logloss: 0.00480423\n",
      "[67]\ttraining's binary_logloss: 0.0047462\n",
      "[68]\ttraining's binary_logloss: 0.00469063\n",
      "[69]\ttraining's binary_logloss: 0.00463467\n",
      "[70]\ttraining's binary_logloss: 0.00458001\n",
      "[71]\ttraining's binary_logloss: 0.00452704\n",
      "[72]\ttraining's binary_logloss: 0.00447453\n",
      "[73]\ttraining's binary_logloss: 0.0044233\n",
      "[74]\ttraining's binary_logloss: 0.0043719\n",
      "[75]\ttraining's binary_logloss: 0.00432169\n",
      "[76]\ttraining's binary_logloss: 0.00427196\n",
      "[77]\ttraining's binary_logloss: 0.00422257\n",
      "[78]\ttraining's binary_logloss: 0.0041742\n",
      "[79]\ttraining's binary_logloss: 0.00412574\n",
      "[80]\ttraining's binary_logloss: 0.00407881\n",
      "[81]\ttraining's binary_logloss: 0.00403437\n",
      "[82]\ttraining's binary_logloss: 0.00399128\n",
      "[83]\ttraining's binary_logloss: 0.0039477\n",
      "[84]\ttraining's binary_logloss: 0.00390542\n",
      "[85]\ttraining's binary_logloss: 0.00386364\n",
      "[86]\ttraining's binary_logloss: 0.00382216\n",
      "[87]\ttraining's binary_logloss: 0.00378197\n",
      "[88]\ttraining's binary_logloss: 0.00374217\n",
      "[89]\ttraining's binary_logloss: 0.00370373\n",
      "[90]\ttraining's binary_logloss: 0.00366519\n",
      "[91]\ttraining's binary_logloss: 0.00362696\n",
      "[92]\ttraining's binary_logloss: 0.00358843\n",
      "[93]\ttraining's binary_logloss: 0.00355079\n",
      "[94]\ttraining's binary_logloss: 0.00351364\n",
      "[95]\ttraining's binary_logloss: 0.0034765\n",
      "[96]\ttraining's binary_logloss: 0.00344084\n",
      "[97]\ttraining's binary_logloss: 0.00340572\n",
      "[98]\ttraining's binary_logloss: 0.00337086\n",
      "[99]\ttraining's binary_logloss: 0.00333685\n",
      "[100]\ttraining's binary_logloss: 0.00330251\n",
      "Save model...\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_train)\n",
    "\n",
    "print('Save model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "(133797, 100)\n",
      "[[59 54 52 62 40 40 42 41 51 56 39 49 37 59 31 62 59 62 61 24 33 46 51 59\n",
      "  54 62 57 57 56 63 41 42 42 40 40 45 45 38 34 46 59 29 63 29 39 33 39 24\n",
      "  10 61 37 34 34  1  1 53 57 38 43 36 43 55 56 21 60 62 23 54 11 11 39 47\n",
      "   7 53 47 17 19 20 16 17 12 12 22 11  7 47 63 12 36 12 62 20 18 18 43 35\n",
      "  34 16 16 16]\n",
      " [59 54 52 62 40 40 42 53 40 56 39 49 37 59 31 62 59 62 61 24 33 46 51 59\n",
      "  54 62 57 57 56 63 59 42 58 40 61 35 45 38 34 46 59 29 63 29 39 33 60 24\n",
      "  10 61 37 34 34 39 12 53 57 38 43 36 43 55 56 14 60 17 23 54 11 11 39 47\n",
      "   7 53 47 17 19 20 16 17 12 12 14 11  7 47 63 12 36 12 62 20 18 18 43 35\n",
      "  34 16 16 16]\n",
      " [59 54 52 62 40 40 42 41 51 56 14 49 13 57 50 62 59 62 61 62 53 46 51 59\n",
      "  54 62 57 57 56 63 41 53 42 40 40  6  8  8  8 46  6 19 63 27 18 62 53 24\n",
      "   9 28 28 54  4 16 14 53 57 28 35 28 43 12 46 38 43 14  3 43  3  3 39 47\n",
      "   7 53 47  5  5  6  6  5 20 20  5 39 19 16 14 14 36 14 62 35  4  4  4 35\n",
      "  34 15  7  7]]\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "# predict and get data on leaves, training data\n",
    "y_pred = gbm.predict(X_train, pred_leaf=True)\n",
    "\n",
    "print(np.array(y_pred).shape)\n",
    "print(y_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed training data\n"
     ]
    }
   ],
   "source": [
    "print('Writing transformed training data')\n",
    "transformed_training_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int32)  # N * num_tress * num_leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_training_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed validating data\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test, pred_leaf=True)\n",
    "print('Writing transformed validating data')\n",
    "transformed_validating_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int32)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_validating_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65901, 100)\n",
      "[[59 63 57 62 40 37 38 41 51 33 63 53 61 59 58 62 59 62 61 24 33 54 59 59\n",
      "  60 54 54 55 53 61 41 42 42 40 40 45 62 58 57 63 59  1 36 10 57 18 39 25\n",
      "  10 62 13 13 12  1  1  9 24 43 47 41 60 30 30 21 16 62 26 22  8  8 34  1\n",
      "  26  1  1  1  1  1  1  1 23 38 22 52 47 47 63 12 36 12 28  1  1  1 43 51\n",
      "  52 63 21 21]\n",
      " [59 54 52 62 40 40 42 41 51 56 39 49 37 59 31 62 59 62 61 24 33 46 51 59\n",
      "  54 62 57 57 56 63 41 42 42 40 40 45 45 38 34 46 59 29 63 29 39 33 39 24\n",
      "  10 61 37 34 34  1  1 53 57 38 43 36 43 55 56 21 60 62 23 54 11 11 39 47\n",
      "   7 53 47 17 19 20 16 17 12 12 22 11  7 47 63 12 36 12 62 20 18 18 43 35\n",
      "  34 16 16 16]\n",
      " [59 54 52 62 40 40 42 41 51 56 39 49 37 59 31 62 59 62 61 24 33 46 51 59\n",
      "  54 62 57 57 56 63 41 42 42 40 40 45 45 38 34 46 59 29 63 29 39 33 39 24\n",
      "  10 61 37 34 34  1  1 53 57 38 43 36 43 55 56 21 60 62 23 54 11 11 39 47\n",
      "   7 53 47 17 19 20 16 17 12 12 22 11  7 47 63 12 36 12 62 20 18 18 43 35\n",
      "  34 16 16 16]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(y_pred).shape)\n",
    "print(y_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2',C=0.16) # logistic model construction\n",
    "lr.fit(transformed_training_matrix, y_train)  # fitting the data\n",
    "y_pred_val = lr.predict(transformed_validating_matrix)   # Give the probabilty on each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99993912, 0.9800995 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred_val,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del transformed_training_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lift(prob_data):\n",
    "    prob_data=prob_data.sort_values(by=['Prob'],ascending=False).reset_index(drop=True)\n",
    "    prob_data['cnt']=1.0\n",
    "    prob_data['cumsum']=prob_data.Y.cumsum()\n",
    "    prob_data['cum_cnt'] = prob_data.cnt.cumsum()\n",
    "    prob_data['precision'] = prob_data['cumsum']/prob_data['cum_cnt']\n",
    "    prob_data['recall'] = prob_data['cumsum']/prob_data['cumsum'].max()\n",
    "    lift_data = prob_data[['precision','recall']].groupby(['recall']).min().reset_index()\n",
    "    lift_data['f1'] = (2*lift_data.precision*lift_data.recall)/(lift_data.precision+lift_data.recall)\n",
    "    return lift_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data={'Y':y_test,'Prob':y_pred_val})\n",
    "result_lift = get_lift(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.975124</td>\n",
       "      <td>0.977556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     recall  precision        f1\n",
       "195    0.98   0.975124  0.977556"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lift=result_lift.iloc[1:,:]\n",
    "result_lift[result_lift.f1==result_lift.f1.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b4ba198>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_lift.recall,result_lift.precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_feature, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "# predict and get data on leaves, training data\n",
    "y_pred = gbm.predict(X_feature, pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed training data\n"
     ]
    }
   ],
   "source": [
    "print('Writing transformed training data')\n",
    "transformed_training_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int32)  # N * num_tress * num_leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_training_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.16, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2',C=0.16) # logistic model construction\n",
    "lr.fit(transformed_training_matrix, y_t)  # fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99998493, 0.9955157 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = lr.predict(transformed_training_matrix)   # Give the probabilty on each label\n",
    "f1_score(y_t,y_pred_train,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sampleSubmission.csv',encoding='big5')\n",
    "TXKEY =np.array(submit[\"TXKEY\"])\n",
    "X_test = dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85443, 100)\n",
      "[[43 38 45 39 30 39 40 39 40 35 39 49 37 59 31 62 59 62 61 24 34 35 33 36\n",
      "  29 62 57 57 56 63 42 45 43 41 41 35 45 38 47  4 59 63 63 29 39 33 34 32\n",
      "  10 61 62 62 34 13 12 58 48 38 43 36 19 55 56 14 53 17 23 55 11 11 20 32\n",
      "  29 29 27 17 19 20 16 36 12 12 14 11  7 44 43 12 40 12 62 63 18 18 11 46\n",
      "  47 16 16 16]\n",
      " [59 54 52 62 40 40 42 41 51 56 39 49 37 59 31 62 59 62 61 24 33 46 51 59\n",
      "  54 62 57 57 56 63 41 42 42 40 40 45 45 38 34 46 59 29 63 29 39 33 39 24\n",
      "  10 61 37 34 34  1  1 53 57 38 43 36 43 55 56 21 60 62 23 54 11 11 39 47\n",
      "   7 53 47 17 19 20 16 17 12 12 22 11  7 47 63 12 36 12 62 20 18 18 37 35\n",
      "  34 16 16 16]\n",
      " [55 57 57 50 40 37 38 41 51 33 31 53 32 59 29 46 40 33 40 45 33 54 59 59\n",
      "  58  2  1  2  2  2 41 42 42 40 40 45 62 58 22 63 28 17  2 21 20 34 39 25\n",
      "  60 57 43 40 40  1  1 21 10 15 31 20 37 30 30 21 16  8 26 22  8  8  4  1\n",
      "  26  1  1 24 26 27 23 25  1  1 22  1 47 47 63 46  7 44 55 26 29 28 43 10\n",
      "  10 34 43 14]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test, pred_leaf=True)\n",
    "\n",
    "print(np.array(y_pred).shape)\n",
    "print(y_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_testing_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_testing_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict_proba(transformed_testing_matrix)   # Give the probabilty on each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({'p0':y_pred_test[:,0],'p1':y_pred_test[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "偽冒機率門檻： 0.5251639050001263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#submit = pd.read_csv('sampleSubmission.csv',encoding='big5')\n",
    "out = pd.concat([submit, df_p], axis=1, ignore_index=True)\n",
    "out.sort_values(by=[3], ascending=False, inplace=True)\n",
    "out.rename(columns={0:'TXKEY', 1:'Class', 2:'p0', 3:'p1'},inplace=True)\n",
    "print('偽冒機率門檻：',out.iloc[134,3])\n",
    "out.Class[out.p1>=out.iloc[134,3]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl= out['Class'].sum()\n",
    "ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out[['TXKEY','Class']]\n",
    "out.to_csv(\"CCTXN_to_kaggle.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This submission: public score: 0.88888\n"
     ]
    }
   ],
   "source": [
    "print('This submission: public score: 0.88888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
