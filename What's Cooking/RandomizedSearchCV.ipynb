{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# set path\n",
    "import os\n",
    "default_path = \"/Users/francislin/jrml/What's Cooking/\"\n",
    "os.chdir(default_path)\n",
    "\n",
    "# skip interaction warning\n",
    "import warnings; \n",
    "warnings.filterwarnings('ignore')\n",
    "#你可以选择修改 ast_note_iteractively kernel 选项来使得 Jupyter 为每一行的变量或语句执行这个操作，以便你可以立即看到多条语句一起输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cuisine', 'id', 'used_pepper', 'used_salt', 'used_oil', 'used_garlic',\n",
       "       'used_ground', 'used_fresh', 'used_sauce', 'used_sugar',\n",
       "       ...\n",
       "       'used_snapper', 'used_graham', 'used_tortellini', 'used_bones',\n",
       "       'used_methi', 'used_cachaca', 'used_hamburger', 'used_candied',\n",
       "       'used_grapeseed', 'used_superfine'],\n",
       "      dtype='object', length=702)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('all_data.pickle','rb') as f:\n",
    "    df= pickle.load(f)\n",
    "# 區分train test\n",
    "dataTrain = df[pd.notnull(df['cuisine'])]\n",
    "dataTest = df[~pd.notnull(df['cuisine'])]\n",
    "dataTrain.columns\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine             object\n",
       "id                   int64\n",
       "used_pepper          int64\n",
       "used_salt            int64\n",
       "used_oil             int64\n",
       "used_garlic          int64\n",
       "used_ground          int64\n",
       "used_fresh           int64\n",
       "used_sauce           int64\n",
       "used_sugar           int64\n",
       "used_onions          int64\n",
       "used_cheese          int64\n",
       "used_chicken         int64\n",
       "used_olive           int64\n",
       "used_black           int64\n",
       "used_water           int64\n",
       "used_red             int64\n",
       "used_flour           int64\n",
       "used_butter          int64\n",
       "used_tomatoes        int64\n",
       "used_green           int64\n",
       "used_powder          int64\n",
       "used_chopped         int64\n",
       "used_cloves          int64\n",
       "used_juice           int64\n",
       "used_white           int64\n",
       "used_onion           int64\n",
       "used_eggs            int64\n",
       "used_rice            int64\n",
       "used_cream           int64\n",
       "                     ...  \n",
       "used_prunes          int64\n",
       "used_slaw            int64\n",
       "used_blue            int64\n",
       "used_semi            int64\n",
       "used_table           int64\n",
       "used_substitute      int64\n",
       "used_peach           int64\n",
       "used_vodka           int64\n",
       "used_crackers        int64\n",
       "used_on              int64\n",
       "used_double          int64\n",
       "used_topping         int64\n",
       "used_paper           int64\n",
       "used_vinaigrette     int64\n",
       "used_poppy           int64\n",
       "used_cutlets         int64\n",
       "used_shanks          int64\n",
       "used_skimmed         int64\n",
       "used_ear             int64\n",
       "used_wild            int64\n",
       "used_snapper         int64\n",
       "used_graham          int64\n",
       "used_tortellini      int64\n",
       "used_bones           int64\n",
       "used_methi           int64\n",
       "used_cachaca         int64\n",
       "used_hamburger       int64\n",
       "used_candied         int64\n",
       "used_grapeseed       int64\n",
       "used_superfine       int64\n",
       "Length: 702, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTrain = dataTrain\n",
    "#去掉y\n",
    "dataTest = dataTest.drop('cuisine',axis=1)\n",
    "#去掉key\n",
    "X_feature = dataTrain.drop(['id','cuisine'],axis=1)\n",
    "y_t =dataTrain['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把上面dataTrain.columns的結果貼到dataTrain，再去掉'Survived'\n",
    "from sklearn.model_selection import train_test_split\n",
    "#拿掉feature_importances低的因子\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y_t, test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-867beca343a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m LGBM_Rand = RandomizedSearchCV(estimator, param_distributions=param_dist,\n\u001b[1;32m     14\u001b[0m                                    n_iter=n_iter_search)\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mLGBM_Rand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameters found by grid search are:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLGBM_Rand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mcandidate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0mn_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "# Random Search\n",
    "print('Start training...')\n",
    "estimator = lgb.LGBMClassifier(boosting_type='gbdt', object='multiclass', num_class=20, random_state=0) \n",
    "\n",
    "param_dist = {\"max_depth\": [3, 7],\n",
    "              \"learning_rate\":random.uniform(0.01, 0.15),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "n_iter_search = 2\n",
    "LGBM_Rand = RandomizedSearchCV(estimator, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "LGBM_Rand.fit(X_train, y_train)\n",
    "print('Best parameters found by grid search are:', LGBM_Rand.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "Predicting is over\n"
     ]
    }
   ],
   "source": [
    "# Final Model\n",
    "evals_result = {} \n",
    "print('Start predicting...')\n",
    "LGBM_Rand_final = lgb.LGBMClassifier(boosting_type='gbdt', object='multiclass', num_class=20, random_state=0,\n",
    "                              criterion = LGBM_Rand.best_params_['criterion'],\n",
    "                                min_samples_split = LGBM_Rand.best_params_['min_samples_split'], \n",
    "                             min_samples_leaf = LGBM_Rand.best_params_['min_samples_leaf'],\n",
    "                             max_depth = LGBM_Rand.best_params_['max_depth']\n",
    "                                    )\n",
    "LGBM_Rand_final_fit = LGBM_Rand_final.fit(X_train, y_train)\n",
    "print(\"Predicting is over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= LGBM_Rand_final_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65178571, 0.44970414, 0.7424594 , 0.80470588, 0.6367713 ,\n",
       "       0.60471204, 0.73841555, 0.87669801, 0.51592357, 0.83873487,\n",
       "       0.72473868, 0.76092545, 0.77657267, 0.90678825, 0.76102088,\n",
       "       0.44736842, 0.72944585, 0.55309735, 0.78403275, 0.61971831])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6961809539587648"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7796027822006202"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred,average=None)\n",
    "f1_score(y_test,y_pred,average='macro')\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
