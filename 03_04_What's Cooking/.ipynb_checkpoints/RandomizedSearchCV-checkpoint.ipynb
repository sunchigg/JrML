{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# load package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# set path\n",
    "import os\n",
    "default_path = \"/Users/francislin/temp/\"\n",
    "os.chdir(default_path)\n",
    "\n",
    "# skip interaction warning\n",
    "import warnings; \n",
    "warnings.filterwarnings('ignore')\n",
    "#你可以选择修改 ast_note_iteractively kernel 选项来使得 Jupyter 为每一行的变量或语句执行这个操作，以便你可以立即看到多条语句一起输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cuisine', 'id', 'used_pepper', 'used_salt', 'used_oil', 'used_garlic',\n",
       "       'used_ground', 'used_fresh', 'used_sauce', 'used_sugar',\n",
       "       ...\n",
       "       'used_hock', 'used_rose', 'used_ciabatta', 'used_ready', 'used_regular',\n",
       "       'used_glass', 'used_safflower', 'used_jeera', 'used_Oil', 'used_oven'],\n",
       "      dtype='object', length=902)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('all_data.pickle','rb') as f:\n",
    "    df= pickle.load(f)\n",
    "# 區分train test\n",
    "dataTrain = df[pd.notnull(df['cuisine'])]\n",
    "dataTest = df[~pd.notnull(df['cuisine'])]\n",
    "dataTrain.columns\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTrain = dataTrain\n",
    "#去掉y\n",
    "dataTest = dataTest.drop('cuisine',axis=1)\n",
    "#去掉key\n",
    "X_feature = dataTrain.drop(['id','cuisine'],axis=1)\n",
    "y_t =dataTrain['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把上面dataTrain.columns的結果貼到dataTrain，再去掉'Survived'\n",
    "from sklearn.model_selection import train_test_split\n",
    "#拿掉feature_importances低的因子\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y_t, test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Best parameters found by grid search are: {'bagging_fraction': 0.08444277806509103, 'criterion': 'gini', 'feature_fraction': 0.10058710182988562, 'learning_rate': 0.3192946626543764, 'max_depth': 7, 'min_samples_leaf': 5, 'reg_lambda': 1.759135534346029}\n",
      "CPU times: user 11min 6s, sys: 2min 41s, total: 13min 48s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import randint as sp_randint\n",
    "# Random Search\n",
    "print('Start training...')\n",
    "estimator = lgb.LGBMClassifier(boosting_type='gbdt', object='multiclass', num_class=20, random_state=0) \n",
    "\n",
    "param_dist = {\"learning_rate\": expon(scale=.1),\n",
    "              \"feature_fraction\": expon(scale=.1),\n",
    "              \"bagging_fraction\": expon(scale=.1),\n",
    "              \"max_depth\": [3, 7],\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"reg_lambda\": expon(scale=10),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "n_iter_search = 10\n",
    "LGBM_Rand = RandomizedSearchCV(estimator, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, random_state=0)\n",
    "LGBM_Rand.fit(X_train, y_train)\n",
    "print('Best parameters found by grid search are:', LGBM_Rand.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "Predicting is over\n"
     ]
    }
   ],
   "source": [
    "# Final Model\n",
    "evals_result = {} \n",
    "print('Start predicting...')\n",
    "LGBM_Rand_final = lgb.LGBMClassifier(boosting_type='gbdt', object='multiclass', num_class=20, random_state=0,\n",
    "                                     learning_rate = LGBM_Rand.best_params_['learning_rate'],\n",
    "                              feature_fraction = LGBM_Rand.best_params_['feature_fraction'],\n",
    "                                bagging_fraction = LGBM_Rand.best_params_['bagging_fraction'], \n",
    "                             min_samples_leaf = LGBM_Rand.best_params_['min_samples_leaf'],\n",
    "                             max_depth = LGBM_Rand.best_params_['max_depth'],\n",
    "                                     criterion = LGBM_Rand.best_params_['criterion']\n",
    "                                    )\n",
    "LGBM_Rand_final_fit = LGBM_Rand_final.fit(X_train, y_train)\n",
    "print(\"Predicting is over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= LGBM_Rand_final_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62222222, 0.46280992, 0.74299065, 0.80924171, 0.68161435,\n",
       "       0.62943495, 0.74961598, 0.88701162, 0.52173913, 0.84269881,\n",
       "       0.8041958 , 0.77040816, 0.7751606 , 0.9057377 , 0.77097506,\n",
       "       0.42922374, 0.73710602, 0.56578947, 0.78644764, 0.62817552])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.706129953058909"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7861392776334535"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred,average=None)\n",
    "f1_score(y_test,y_pred,average='macro')\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拿全部的dataTrain來建\n",
    "LGBM_Rand_final_fit_all = LGBM_Rand_final_fit.fit(X_feature, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest = dataTest.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_Rand_final_fit_res =LGBM_Rand_final_fit_all.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['british', 'southern_us', 'italian', ..., 'italian', 'southern_us',\n",
       "       'mexican'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_Rand_final_fit_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=pd.read_csv(\"/Users/francislin/jrml/What's Cooking/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['cuisine'] = LGBM_Rand_final_fit_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/francislin/temp'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "submit.to_csv(\"/Users/francislin/jrml/What's Cooking/submit_to_kaggle.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
