{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "default_path = '/Users/Rex/Desktop'\n",
    "os.chdir(default_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   udnew       OI     net  opmcl    short\n",
      "2   27.0  56979.0 -1121.0   38.0  33765.0\n",
      "3  -81.0  57267.0 -1545.0  -24.0  32775.0\n",
      "4  -43.0  57605.0 -3215.0  -32.0  33413.0\n",
      "5  -55.0  57930.0 -5085.0   -9.0  36407.0\n",
      "6   53.0  58371.0  1160.0  -23.0  34722.0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    1\n",
      "6    1\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "data = pd.read_csv(\"rex_22.csv\")\n",
    "#處理資料\n",
    "data_no = data.dropna()\n",
    "\n",
    "x = data_no.drop('y',1)\n",
    "y = data_no['y']\n",
    "x = x.shift(1)\n",
    "\n",
    "x_new = x.drop(1)\n",
    "y_new = y.drop(1)\n",
    "\n",
    "print(x_new[:5])\n",
    "print(y_new[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new['OI'] = np.log(x['OI'])\n",
    "x_new['short'] = np.log(x['short'])\n",
    "x_new['OI*ud'] = x_new['OI']*x_new['udnew']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=1e-06,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'penalty': ['l1', 'l2'], 'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100], 'solver': ['liblinear'], 'multi_class': ['ovr']}, {'penalty': ['l2'], 'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100], 'solver': ['lbfgs'], 'multi_class': ['ovr', 'multinomial']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardlisze,但後來發現不標準化，模型較準，故下面套模型時不使用標準化的特徵\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)\n",
    "\n",
    "#這一段是網路找來的，不確定是否有更好的寫法\n",
    "tuned_parameters=[{'penalty':['l1','l2'],\n",
    "                   'C':[0.01,0.05,0.1,0.5,1,5,10,50,100],\n",
    "                    'solver':['liblinear'],\n",
    "                    'multi_class':['ovr']},\n",
    "                {'penalty':['l2'],\n",
    "                 'C':[0.01,0.05,0.1,0.5,1,5,10,50,100],\n",
    "                'solver':['lbfgs'],\n",
    "                'multi_class':['ovr','multinomial']}]\n",
    "LGGR=GridSearchCV(LogisticRegression(tol=1e-6),tuned_parameters,cv = 10)\n",
    "LGGR.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.5675675675675675\n",
      "[[16 60]\n",
      " [ 4 68]]\n",
      "f1_score: 0.6799999999999999\n",
      "R-squre: -0.7309941520467838\n"
     ]
    }
   ],
   "source": [
    "y_pred = LGGR.predict(x_test)\n",
    "y_pred_prob = LGGR.predict_proba(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"accuracy_score: \"+str(metrics.accuracy_score(y_test,y_pred)))\n",
    "print(confusion)\n",
    "print(\"f1_score: \"+str(metrics.f1_score(y_test,y_pred)))\n",
    "print(\"R-squre: \"+str(metrics.r2_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
